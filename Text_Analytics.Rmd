---
title: "Text Analytics"
author: "Shubham Jadhav"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data Initialization and Clean-up

### Install "tm" package
```{r install_tm}
#install.packages("tm")
```
### Use Library "tm"
```{r use_tm}
library(tm)
library(dplyr)
```
### Create VCorpus
```{r vcorpus}
pom <- VCorpus(DirSource("./Data", ignore.case = TRUE, mode = "text"))
str(pom)
```
```{r print_corpus}
pom
```
### Extract the text from the corpus 
```{r extract_text}
pomtext <- pom[[1]]
pomtext
```
### See the content of the document
```{r see_doc_content}
pomtext[[1]][1:10]
```
### Identify chapters
```{r get_chapters}
pombook <- pomtext[[1]]
chap_idx = c()
for(i in 1:length(pombook)){
  if(grepl("CHAPTER ", pombook[i])){
    chap_idx <- append(chap_idx, i)
    print(pombook[i])
  }
}
```
### Extract Chapters to variables
```{r extract_chapters}
lst_chap_idx <- tail(chap_idx,1)
lst_book_idx <- length(pombook)

pom_chapter <- character()

for(i in seq(1, length(chap_idx))){
  
  from <- chap_idx[i]+1
  
  if(chap_idx[i] == lst_chap_idx){
    to <- lst_book_idx-1
  } else {
    to <- chap_idx[i+1]-1
  }
  
  assign(paste0("chapter_",i), pombook[from:to])

}
```
```{r}
head(chapter_1)
```
### Write Chapters to seperate files
```{r}
if (!dir.exists("./Data/chapters")){
  dir.create("./Data/chapters")
}else{
  print("Chapters dir exists")
}

for(i in seq(1, length(chap_idx))){
  ch <- get(eval(paste0("chapter_",i)))
  file <- paste("./Data/chapters/chapter_",i,".txt")
  
  write.table(ch, file=file, sep="\t", row.names=FALSE, col.names=FALSE,quote=FALSE);
}
```
### Get VCorpus from the chapters
```{r vcorpus2}
pom2 <- VCorpus(DirSource("./Data/chapters", ignore.case = TRUE, mode = "text"))
str(pom2)
```
```{r print_corpus2}
pom2
```
```{r longest_words_sentences}

for(ch in 1:length(chap_idx)){
  curr_chapter <- get(eval(paste0("chapter_",ch)))
  
  len <- length(curr_chapter)
  word_list <- character()
  all_sentence <- character()
  sentence_list <- character()
  
  for(i in 1:len){
    words <- c(strsplit(curr_chapter[i], split=" ")[[1]])
    word_list <- append(word_list, words)
    all_sentence <- paste(all_sentence, curr_chapter[i])
  }
  
  sentence_list <- c(strsplit(all_sentence, split="[.]")[[1]])
  
  word_len <- nchar(word_list)
  word_df <- data.frame("word" = word_list, "word_len" = word_len)
  word_df <- word_df %>% arrange(desc(word_len))
  assign(paste0("df_lon_wrd_chap_",ch), word_df[1:10,])
  
  sen_len <- nchar(sentence_list)
  sen_df <- data.frame("sentence" = sentence_list, "sentence_len" = sen_len)
  sen_df <- sen_df %>% arrange(desc(sen_len))
  assign(paste0("df_lon_sen_chap_",ch), sen_df[1:10,])

  if(ch < 12){
    print(paste("Longest words and sentences for chapter",ch))
    print(get(eval(paste0("df_lon_wrd_chap_",ch))))
    print(get(eval(paste0("df_lon_sen_chap_",ch))))
  }
}
```

### Document term matrix (DTM)
```{r ch1dtm}
pomdtm <- DocumentTermMatrix(pom2)
pomdtm
```
```{r}
inspect(pomdtm)
```
```{r}
str(pomdtm)
```
### Term Document matrix
```{r tdm}
pomtdm <- TermDocumentMatrix(pom2)
pomtdm
```

## Corpus Cleansing â€“ Data Wrangling

### Remove Punctuations
```{r removepuncfunc}
removePunc <- function(x) gsub("[^[:alpha:][:space:]]*","",x)
removePunc
```
```{r}
pomcl <- tm::tm_map(pom2, content_transformer(removePunc))
pomcl
```
```{r}
str(pomcl)
```
```{r}
inspect(pomcl)
```
### To Lower case
```{r lowercase}
pomlow <- tm::tm_map(pomcl, content_transformer(tolower))
pomlow
```
```{r}
str(pomlow)
```
```{r}
inspect(pomlow)
```
### Compute the Document Term Matric (DTM)
```{r}
pomdtm <- DocumentTermMatrix(pomlow)
pomdtm
```
```{r}
str(pomdtm)
```
```{r}
inspect(pomdtm)
```
### Remove Sparsity
```{r}
sparse_low <- removeSparseTerms(pomtdm, 0.5)
sparse_low
```
### Remove Stop words
```{r rmstopwords}
myStopwords<- c(tm::stopwords("english"))
myStopwords[1:20]
```
```{r}
pomstop <- tm::tm_map(pomlow, tm::removeWords, myStopwords)
pomstop
```
```{r}
inspect(pomstop[[1]])
```
### Create TDM
```{r wostopwrdtdm}
pomstoptdm <- tm::TermDocumentMatrix(pomstop)
pomstoptdm
```
### Find Frequency of words
```{r freq5}
freqterm5 <- tm::findFreqTerms(pomstoptdm, lowfreq = 5)
freqterm5[1:20]
```
```{r freq10}
freqterm10 <- tm::findFreqTerms(pomstoptdm, lowfreq = 10)
freqterm10[1:20]
```
```{r freq20}
freqterm20 <- tm::findFreqTerms(pomstoptdm, lowfreq = 20)
freqterm20[1:20]
```
```{r freq50}
freqterm50 <- tm::findFreqTerms(pomstoptdm, lowfreq = 50)
freqterm50[1:20]
```
```{r freqwcnt}
for(i in 1:11){
  assign(paste0("pomtf_chap",i), tm::termFreq(pomstop[[i]]))
  print(paste("For chapter",i))
  print(get(eval(paste0("pomtf_chap",i)))[1:5])
}
```
### Dendograms
```{r dendograms}
for(i in 1:11){
  tdm <- tm::TermDocumentMatrix(pomstop[[i]])
  df <- as.data.frame(tdm[[1]])
  pomdist <- dist(df)
  assign(paste0("pomdg_chap",i), hclust(pomdist, method = "ward.D2"))
  
  print(paste("For chapter",i))
  print(str(get(eval(paste0("pomdg_chap",i)))))
}
```
```{r}
for(i in 1:11){
  plot(get(eval(paste0("pomdg_chap",i))), main = paste0("Dendogram - Chapter ",i))
}
```
### Word Cloud
```{r wordcloud}
#install.packages("wordcloud")
library(wordcloud)

words <- names(pomtf_chap1)
words[1:50]
```
```{r}
pal <- brewer.pal(9,"BuGn")
for(i in 1:11){
  print(paste("Wordcloud for chapter",i))
  tf <- get(eval(paste0("pomtf_chap",i)))
  words <- names(tf)
  wordcloud(words, tf, colors = pal[-(1:4)], scale=c(4, .5))
}
```
```{r}
pal2 <- brewer.pal(8,"Spectral")
for(i in 1:11){
  print(paste("Wordcloud for chapter",i))
  tf <- get(eval(paste0("pomtf_chap",i)))
  words <- names(tf)
  wordcloud(words, tf, colors = pal2, scale=c(4, .5))
}
```






















